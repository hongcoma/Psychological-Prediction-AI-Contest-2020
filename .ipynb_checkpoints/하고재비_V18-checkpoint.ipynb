{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ca40348",
   "metadata": {},
   "source": [
    "# V13코드를 기반으로 lightGBM 을 사용한 버전\n",
    "# V17코드를 기반으로 lightGBM 을 사용한 다른 버전"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c0a76c",
   "metadata": {},
   "source": [
    "# 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "951f1aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set() # setting seaborn default for plots\n",
    "\n",
    "def bar_chart(feature):\n",
    "    yes = train[train['voted']==1][feature].value_counts()\n",
    "    no = train[train['voted']==2][feature].value_counts()\n",
    "    df = pd.DataFrame([yes,no])\n",
    "    df.index = ['Yes','No']\n",
    "    df.plot(kind='bar',stacked=True, figsize=(10,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "57b1a445",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train=pd.read_csv('./train.csv')\n",
    "test=pd.read_csv('./test_x.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d66bbb",
   "metadata": {},
   "source": [
    "# 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "5132a1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "train['trust']=1\n",
    "test['trust']=1\n",
    "\n",
    "family_drop_score=10\n",
    "\n",
    "train['trust']=np.where(train['familysize'] >= family_drop_score, 0, train['trust'])\n",
    "test['trust']=np.where(test['familysize'] >= family_drop_score, 0, test['trust'])\n",
    "\n",
    "train['familysize']=np.where(train['familysize'] >= family_drop_score, family_drop_score, train['familysize'])\n",
    "test['familysize']=np.where(test['familysize'] >= family_drop_score, family_drop_score, test['familysize'])\n",
    "\n",
    "train['trust']=np.where(train['education'] == 0, 0, train['trust'])\n",
    "train['education']=np.where(train['education'] == 0, 2, train['education'])\n",
    "test['trust']=np.where(test['education'] == 0, 0, test['trust'])\n",
    "test['education']=np.where(test['education'] == 0, 2, test['education'])\n",
    "\n",
    "train['urban']=train['urban'].astype('str')\n",
    "test['urban']=test['urban'].astype('str')\n",
    "\n",
    "train['education']=train['education'].astype('str')\n",
    "test['education']=test['education'].astype('str')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "cc005109",
   "metadata": {},
   "outputs": [],
   "source": [
    "time = ['QaE', 'QbE', 'QcE', 'QdE', 'QeE','QfE', 'QgE', 'QhE', 'QiE', 'QjE', 'QkE', 'QlE', 'QmE', 'QnE', 'QoE', 'QpE', 'QqE', 'QrE', 'QsE', 'QtE']\n",
    "\n",
    "train[time] = np.where(train[time] > 10000, 10000, train[time])\n",
    "test[time] = np.where(test[time] > 10000, 10000, test[time])\n",
    "\n",
    "# train[time] = np.where(train[time] > 10000, train[time].median(), train[time])\n",
    "# test[time] = np.where(test[time] > 10000, test[time].median(), test[time])\n",
    "\n",
    "P_time=['QbE', 'QcE', 'QhE', 'QjE', 'QmE', 'QoE', 'QpE', 'QsE', 'QtE']\n",
    "N_time=['QaE', 'QdE', 'QeE', 'QfE', 'QgE', 'QiE', 'QkE', 'QlE', 'QnE', 'QqE', 'QrE']\n",
    "\n",
    "train['p_time']=train[P_time].sum(axis=1)\n",
    "test['p_time']=test[P_time].sum(axis=1)\n",
    "train['n_time']=train[N_time].sum(axis=1)\n",
    "test['n_time']=test[N_time].sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f829ef3e",
   "metadata": {},
   "source": [
    "# 원핫 인코딩 (gender, race, religion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "741c771b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.get_dummies(train, columns=['race'])\n",
    "train=pd.get_dummies(train, columns=['religion'])\n",
    "train=pd.get_dummies(train, columns=['urban'])\n",
    "train=pd.get_dummies(train, columns=['hand'])\n",
    "train=pd.get_dummies(train, columns=['gender'])\n",
    "\n",
    "test=pd.get_dummies(test, columns=['race'])\n",
    "test=pd.get_dummies(test, columns=['religion'])\n",
    "test=pd.get_dummies(test, columns=['urban'])\n",
    "test=pd.get_dummies(test, columns=['hand'])\n",
    "test=pd.get_dummies(test, columns=['gender'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "232028a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "label = LabelEncoder()\n",
    "train['age_group_code'] = label.fit_transform(train['age_group'])\n",
    "train['education_code'] = label.fit_transform(train['education'])\n",
    "\n",
    "test['age_group_code'] = label.fit_transform(test['age_group'])\n",
    "test['education_code'] = label.fit_transform(test['education'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4cb1a4",
   "metadata": {},
   "source": [
    "# Feature : Mach_score (마키아벨리니즘 스코어)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "5f73d7a8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Answers = ['QaA', 'QbA', 'QcA', 'QdA', 'QeA',\n",
    "             'QfA', 'QgA', 'QhA', 'QiA', 'QjA', \n",
    "             'QkA', 'QlA', 'QmA', 'QnA', 'QoA', \n",
    "             'QpA', 'QqA', 'QrA', 'QsA', 'QtA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "f031affe",
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse = [\"QeA\", \"QfA\", \"QkA\", \"QqA\", \"QrA\"]\n",
    "for r in reverse: \n",
    "        train[r] = 6 - train[r]\n",
    "        test[r] = 6 - test[r]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "329ca96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse = [\"QaA\", \"QdA\", \"QgA\", \"QiA\", \"QnA\"]\n",
    "for r in reverse: \n",
    "        train[r] = 6 - train[r]\n",
    "        test[r] = 6 - test[r]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "c589c845",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Mach_score'] = train[Answers].mean(axis = 1)\n",
    "test['Mach_score'] = test[Answers].mean(axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3acad36",
   "metadata": {},
   "source": [
    "# Feature : tp0106, tp0207, tp0308, tp0409, tp0510 (관련있는 tp 끼리 묶음)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "3d213727",
   "metadata": {},
   "outputs": [],
   "source": [
    "Tp = ['tp01', 'tp02', 'tp03', 'tp04', 'tp05',\n",
    "             'tp06', 'tp07', 'tp08', 'tp09', 'tp10']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "f5c66c11",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reverse = [\"tp06\", \"tp07\", \"tp08\", \"tp09\", \"tp10\"]\n",
    "for r in reverse: \n",
    "        train[r] = 7 - train[r]\n",
    "        test[r] = 7 - test[r]\n",
    "        \n",
    "tp0106=['tp01', 'tp06']\n",
    "tp0207=['tp02', 'tp07']\n",
    "tp0308=['tp03', 'tp08']\n",
    "tp0409=['tp04', 'tp09']\n",
    "tp0510=['tp05', 'tp10']\n",
    "train['tp0106'] = train[tp0106].sum(axis = 1)\n",
    "train['tp0207'] = train[tp0207].sum(axis = 1)\n",
    "train['tp0308'] = train[tp0308].sum(axis = 1)\n",
    "train['tp0409'] = train[tp0409].sum(axis = 1)\n",
    "train['tp0510'] = train[tp0510].sum(axis = 1)\n",
    "temp=['tp0106', 'tp0207', 'tp0308','tp0409', 'tp0510']\n",
    "\n",
    "test['tp0106'] = test[tp0106].sum(axis = 1)\n",
    "test['tp0207'] = test[tp0207].sum(axis = 1)\n",
    "test['tp0308'] = test[tp0308].sum(axis = 1)\n",
    "test['tp0409'] = test[tp0409].sum(axis = 1)\n",
    "test['tp0510'] = test[tp0510].sum(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "0ee93748",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tp0106</th>\n",
       "      <th>tp0207</th>\n",
       "      <th>tp0308</th>\n",
       "      <th>tp0409</th>\n",
       "      <th>tp0510</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>45532.000000</td>\n",
       "      <td>45532.000000</td>\n",
       "      <td>45532.000000</td>\n",
       "      <td>45532.000000</td>\n",
       "      <td>45532.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>7.545023</td>\n",
       "      <td>7.590090</td>\n",
       "      <td>5.261486</td>\n",
       "      <td>7.763749</td>\n",
       "      <td>4.017921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.509913</td>\n",
       "      <td>2.916658</td>\n",
       "      <td>3.043976</td>\n",
       "      <td>3.366161</td>\n",
       "      <td>2.473560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>11.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>14.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>14.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tp0106        tp0207        tp0308        tp0409        tp0510\n",
       "count  45532.000000  45532.000000  45532.000000  45532.000000  45532.000000\n",
       "mean       7.545023      7.590090      5.261486      7.763749      4.017921\n",
       "std        3.509913      2.916658      3.043976      3.366161      2.473560\n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000\n",
       "25%        5.000000      6.000000      3.000000      5.000000      2.000000\n",
       "50%        8.000000      8.000000      5.000000      8.000000      4.000000\n",
       "75%       11.000000     10.000000      7.000000     11.000000      6.000000\n",
       "max       14.000000     14.000000     14.000000     14.000000     14.000000"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[temp].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "82b7ce3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tp_drop_score=12\n",
    "\n",
    "train['trust']=np.where(train['tp0106'] >= tp_drop_score, 0, train['trust'])\n",
    "train['trust']=np.where(train['tp0207'] >= tp_drop_score, 0, train['trust'])\n",
    "train['trust']=np.where(train['tp0308'] >= tp_drop_score, 0, train['trust'])\n",
    "train['trust']=np.where(train['tp0409'] >= tp_drop_score, 0, train['trust'])\n",
    "train['trust']=np.where(train['tp0510'] >= tp_drop_score, 0, train['trust'])\n",
    "\n",
    "test['trust']=np.where(test['tp0106'] >= tp_drop_score, 0, test['trust'])\n",
    "test['trust']=np.where(test['tp0207'] >= tp_drop_score, 0, test['trust'])\n",
    "test['trust']=np.where(test['tp0308'] >= tp_drop_score, 0, test['trust'])\n",
    "test['trust']=np.where(test['tp0409'] >= tp_drop_score, 0, test['trust'])\n",
    "test['trust']=np.where(test['tp0510'] >= tp_drop_score, 0, test['trust'])\n",
    "\n",
    "train['tp0106']=np.where(train['tp0106'] >= tp_drop_score, tp_drop_score, train['tp0106'])\n",
    "train['tp0207']=np.where(train['tp0207'] >= tp_drop_score, tp_drop_score, train['tp0207'])\n",
    "train['tp0308']=np.where(train['tp0308'] >= tp_drop_score, tp_drop_score, train['tp0308'])\n",
    "train['tp0409']=np.where(train['tp0409'] >= tp_drop_score, tp_drop_score, train['tp0409'])\n",
    "train['tp0510']=np.where(train['tp0510'] >= tp_drop_score, tp_drop_score, train['tp0510'])\n",
    "\n",
    "test['tp0106']=np.where(test['tp0106'] >= tp_drop_score, tp_drop_score, test['tp0106'])\n",
    "test['tp0207']=np.where(test['tp0207'] >= tp_drop_score, tp_drop_score, test['tp0207'])\n",
    "test['tp0308']=np.where(test['tp0308'] >= tp_drop_score, tp_drop_score, test['tp0308'])\n",
    "test['tp0409']=np.where(test['tp0409'] >= tp_drop_score, tp_drop_score, test['tp0409'])\n",
    "test['tp0510']=np.where(test['tp0510'] >= tp_drop_score, tp_drop_score, test['tp0510'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea7ff505",
   "metadata": {},
   "source": [
    "# wr에서 가져갈 feature : 1, 3, 5, 6, 9, 11"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e01335",
   "metadata": {},
   "source": [
    "# wf_(1~3) : 설문자의 어휘 능력 (허구인 단어의 정의를 앎)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "ae88ab68",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wf=['wf_01', 'wf_02', 'wf_03']\n",
    "\n",
    "train['wf']=train[wf].mean(axis=1)\n",
    "train['trust']= np.where(train['wf'] >= 0.0, 0, train['trust'])\n",
    "\n",
    "test['wf']=test[wf].mean(axis=1)\n",
    "test['trust']= np.where(test['wf'] >= 0.0, 0, test['trust'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab06e14f",
   "metadata": {},
   "source": [
    "# drop 할 feature들"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "a0686027",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_feature=[\n",
    "#                 'engnat',\n",
    "    \n",
    "#                 'familysize',\n",
    "    \n",
    "#                 'married',\n",
    "    \n",
    "#                 'race_Arab', 'race_Asian','race_Black','race_Indigenous Australian','race_Native American','race_Other','race_White',               \n",
    "    \n",
    "#                 'religion_Agnostic','religion_Atheist', 'religion_Buddhist','religion_Christian_Catholic','religion_Christian_Mormon', \n",
    "#                 'religion_Christian_Other', 'religion_Christian_Protestant', 'religion_Hindu','religion_Jewish','religion_Muslim', \n",
    "#                 'religion_Other','religion_Sikh',\n",
    "    \n",
    "#                 'gender_Female','gender_Male',\n",
    "                \n",
    "#                 'urban_0','urban_1','urban_2','urban_3',\n",
    "    \n",
    "                'education',\n",
    "    \n",
    "#                 'trust',\n",
    "                \n",
    "                'age_group',\n",
    "                \n",
    "                'QaA', 'QbA', 'QcA', 'QdA', 'QeA','QfA', 'QgA', 'QhA', 'QiA', 'QjA', 'QkA', 'QlA', 'QmA', 'QnA', 'QoA','QpA', \n",
    "                'QqA', 'QrA', 'QsA', 'QtA',\n",
    "                \n",
    "                'QaE', 'QbE', 'QcE', 'QdE', 'QeE', 'QfE', 'QgE', 'QhE', 'QiE', 'QjE', 'QkE', 'QlE','QmE', 'QnE', 'QoE', 'QpE', \n",
    "                'QqE', 'QrE', 'QsE', 'QtE',\n",
    "    \n",
    "#                 'p_time' , \n",
    "\n",
    "#                 'n_time',\n",
    "              \n",
    "                'tp01', 'tp02', 'tp03', 'tp04', 'tp05','tp06','tp07', 'tp08', 'tp09', 'tp10',\n",
    "              \n",
    "#                 'wr_01', 'wr_02', 'wr_03', 'wr_04', 'wr_05', 'wr_06', 'wr_07', 'wr_08', 'wr_09','wr_10','wr_11', 'wr_12', 'wr_13', \n",
    "                'wr_02',  'wr_04', 'wr_07', 'wr_08', 'wr_10', 'wr_12', 'wr_13', \n",
    "                'wf_01', 'wf_02', 'wf_03', 'wf',\n",
    "              \n",
    "                'hand_0','hand_1','hand_2','hand_3',\n",
    "              \n",
    "              ]\n",
    "\n",
    "train = train.drop(drop_feature, axis = 1)\n",
    "test = test.drop(drop_feature, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90b6eae",
   "metadata": {},
   "source": [
    "# Model 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "ddc2ea46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c8e33a",
   "metadata": {},
   "source": [
    "# 사용한 feature 목록"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "65fb6275",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index\n",
      "age_group\n",
      "education\n",
      "engnat\n",
      "familysize\n",
      "married\n",
      "voted\n",
      "wr_01\n",
      "wr_03\n",
      "wr_05\n",
      "wr_06\n",
      "wr_09\n",
      "wr_11\n",
      "trust\n",
      "p_time\n",
      "n_time\n",
      "race_Arab\n",
      "race_Asian\n",
      "race_Black\n",
      "race_Indigenous Australian\n",
      "race_Native American\n",
      "race_Other\n",
      "race_White\n",
      "religion_Agnostic\n",
      "religion_Atheist\n",
      "religion_Buddhist\n",
      "religion_Christian_Catholic\n",
      "religion_Christian_Mormon\n",
      "religion_Christian_Other\n",
      "religion_Christian_Protestant\n",
      "religion_Hindu\n",
      "religion_Jewish\n",
      "religion_Muslim\n",
      "religion_Other\n",
      "religion_Sikh\n",
      "urban_0\n",
      "urban_1\n",
      "urban_2\n",
      "urban_3\n",
      "gender_Female\n",
      "gender_Male\n",
      "age_group_code\n",
      "education_code\n",
      "Mach_score\n",
      "tp0106\n",
      "tp0207\n",
      "tp0308\n",
      "tp0409\n",
      "tp0510\n"
     ]
    }
   ],
   "source": [
    "for i in train:\n",
    "    print(i)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e092ef",
   "metadata": {},
   "source": [
    "# 모델 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "2b2db252",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import *\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "import warnings\n",
    "import gc\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "X = train.copy()\n",
    "X.drop('voted', axis=1, inplace = True)\n",
    "Y = train['voted']\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "f705b886",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "DataFrame.dtypes for data must be int, float or bool.\nDid not expect the data types in the following fields: age_group, education",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [117]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlightgbm\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mlgb\u001b[39;00m\n\u001b[0;32m      3\u001b[0m model\u001b[38;5;241m=\u001b[39mlgb\u001b[38;5;241m.\u001b[39mLGBMClassifier()\n\u001b[1;32m----> 4\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pybook\\lib\\site-packages\\lightgbm\\sklearn.py:967\u001b[0m, in \u001b[0;36mLGBMClassifier.fit\u001b[1;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[0;32m    964\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    965\u001b[0m             valid_sets[i] \u001b[38;5;241m=\u001b[39m (valid_x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_le\u001b[38;5;241m.\u001b[39mtransform(valid_y))\n\u001b[1;32m--> 967\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_sets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    968\u001b[0m \u001b[43m            \u001b[49m\u001b[43meval_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_sample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    969\u001b[0m \u001b[43m            \u001b[49m\u001b[43meval_class_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_class_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_init_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_init_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    970\u001b[0m \u001b[43m            \u001b[49m\u001b[43meval_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_metric\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    971\u001b[0m \u001b[43m            \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcategorical_feature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcategorical_feature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    972\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_model\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    973\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pybook\\lib\\site-packages\\lightgbm\\sklearn.py:748\u001b[0m, in \u001b[0;36mLGBMModel.fit\u001b[1;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[0;32m    745\u001b[0m evals_result \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    746\u001b[0m callbacks\u001b[38;5;241m.\u001b[39mappend(record_evaluation(evals_result))\n\u001b[1;32m--> 748\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    749\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    750\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    751\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_boost_round\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_estimators\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    752\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalid_sets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_sets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    753\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalid_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    754\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    755\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_metrics_callable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    756\u001b[0m \u001b[43m    \u001b[49m\u001b[43minit_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    757\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeature_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    758\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\n\u001b[0;32m    759\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    761\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m evals_result:\n\u001b[0;32m    762\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_evals_result \u001b[38;5;241m=\u001b[39m evals_result\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pybook\\lib\\site-packages\\lightgbm\\engine.py:271\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[0;32m    269\u001b[0m \u001b[38;5;66;03m# construct booster\u001b[39;00m\n\u001b[0;32m    270\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 271\u001b[0m     booster \u001b[38;5;241m=\u001b[39m \u001b[43mBooster\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_set\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    272\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_valid_contain_train:\n\u001b[0;32m    273\u001b[0m         booster\u001b[38;5;241m.\u001b[39mset_train_data_name(train_data_name)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pybook\\lib\\site-packages\\lightgbm\\basic.py:2605\u001b[0m, in \u001b[0;36mBooster.__init__\u001b[1;34m(self, params, train_set, model_file, model_str, silent)\u001b[0m\n\u001b[0;32m   2598\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_network(\n\u001b[0;32m   2599\u001b[0m         machines\u001b[38;5;241m=\u001b[39mmachines,\n\u001b[0;32m   2600\u001b[0m         local_listen_port\u001b[38;5;241m=\u001b[39mparams[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlocal_listen_port\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   2601\u001b[0m         listen_time_out\u001b[38;5;241m=\u001b[39mparams\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtime_out\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m120\u001b[39m),\n\u001b[0;32m   2602\u001b[0m         num_machines\u001b[38;5;241m=\u001b[39mparams[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_machines\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   2603\u001b[0m     )\n\u001b[0;32m   2604\u001b[0m \u001b[38;5;66;03m# construct booster object\u001b[39;00m\n\u001b[1;32m-> 2605\u001b[0m \u001b[43mtrain_set\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconstruct\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2606\u001b[0m \u001b[38;5;66;03m# copy the parameters from train_set\u001b[39;00m\n\u001b[0;32m   2607\u001b[0m params\u001b[38;5;241m.\u001b[39mupdate(train_set\u001b[38;5;241m.\u001b[39mget_params())\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pybook\\lib\\site-packages\\lightgbm\\basic.py:1815\u001b[0m, in \u001b[0;36mDataset.construct\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1812\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_init_score_by_predictor(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predictor, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata, used_indices)\n\u001b[0;32m   1813\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1814\u001b[0m     \u001b[38;5;66;03m# create train\u001b[39;00m\n\u001b[1;32m-> 1815\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_lazy_init\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1816\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1817\u001b[0m \u001b[43m                    \u001b[49m\u001b[43minit_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredictor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predictor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1818\u001b[0m \u001b[43m                    \u001b[49m\u001b[43msilent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msilent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeature_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1819\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mcategorical_feature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcategorical_feature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1820\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfree_raw_data:\n\u001b[0;32m   1821\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pybook\\lib\\site-packages\\lightgbm\\basic.py:1474\u001b[0m, in \u001b[0;36mDataset._lazy_init\u001b[1;34m(self, data, label, reference, weight, group, init_score, predictor, silent, feature_name, categorical_feature, params)\u001b[0m\n\u001b[0;32m   1472\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpandas_categorical \u001b[38;5;241m=\u001b[39m reference\u001b[38;5;241m.\u001b[39mpandas_categorical\n\u001b[0;32m   1473\u001b[0m     categorical_feature \u001b[38;5;241m=\u001b[39m reference\u001b[38;5;241m.\u001b[39mcategorical_feature\n\u001b[1;32m-> 1474\u001b[0m data, feature_name, categorical_feature, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpandas_categorical \u001b[38;5;241m=\u001b[39m \u001b[43m_data_from_pandas\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1475\u001b[0m \u001b[43m                                                                                     \u001b[49m\u001b[43mfeature_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1476\u001b[0m \u001b[43m                                                                                     \u001b[49m\u001b[43mcategorical_feature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1477\u001b[0m \u001b[43m                                                                                     \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpandas_categorical\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1478\u001b[0m label \u001b[38;5;241m=\u001b[39m _label_from_pandas(label)\n\u001b[0;32m   1480\u001b[0m \u001b[38;5;66;03m# process for args\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pybook\\lib\\site-packages\\lightgbm\\basic.py:594\u001b[0m, in \u001b[0;36m_data_from_pandas\u001b[1;34m(data, feature_name, categorical_feature, pandas_categorical)\u001b[0m\n\u001b[0;32m    592\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m bad_indices:\n\u001b[0;32m    593\u001b[0m     bad_index_cols_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(data\u001b[38;5;241m.\u001b[39mcolumns[bad_indices])\n\u001b[1;32m--> 594\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataFrame.dtypes for data must be int, float or bool.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    595\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDid not expect the data types in the following fields: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    596\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbad_index_cols_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    597\u001b[0m data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mvalues\n\u001b[0;32m    598\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m data\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mfloat32 \u001b[38;5;129;01mand\u001b[39;00m data\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mfloat64:\n",
      "\u001b[1;31mValueError\u001b[0m: DataFrame.dtypes for data must be int, float or bool.\nDid not expect the data types in the following fields: age_group, education"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "model=lgb.LGBMClassifier()\n",
    "model.fit(x_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bac2b88",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "y_pred=model.predict(x_test)\n",
    "\n",
    "from sklearn.metrics import *\n",
    "\n",
    "def plot_roc_curve(fpr, tpr):\n",
    "    plt.plot(fpr, tpr, color='red', label='ROC')\n",
    "    plt.plot([0, 1], [0, 1], color='green', linestyle='--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic Curve')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "TN, FP, FN, TP = confusion_matrix(y_test, y_pred).ravel()\n",
    "print('accuracy_score (정확도):',accuracy_score(y_test, y_pred))\n",
    "print('precision_score (정밀도) :',TP/(TP+FP))\n",
    "print('recall_score (재현율):',TP/(TP+FN))\n",
    "print('sensitivity_score (민감도(거짓탐색)):',TP/(TP+FN))\n",
    "print('specificity_score (특이도(참탐색)):',TN/(FP+TN))\n",
    "FPR, TPR, thresholds = roc_curve(y_test, y_pred, pos_label=1)\n",
    "print('auc score :',auc(FPR, TPR))\n",
    "print('F1 score :',f1_score(y_test, y_pred))\n",
    "plot_roc_curve(FPR, TPR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630e1f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"train set score:{:.4f}\".format(model.score(x_train, y_train)))\n",
    "\n",
    "print(\"test set score:{:.4f}\".format(model.score(x_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a72bf18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "train_ds = lgb.Dataset(x_train, label = y_train)\n",
    "test_ds = lgb.Dataset(x_test, label = y_test)\n",
    "\n",
    "# X_test 대신에 X_val(for validation)도 가능하다\n",
    "test_set = lgb.Dataset(x_test, label=y_test)\n",
    "params = {\n",
    "    'max_depth' : 3,   # 최대 분기 가능깊이\n",
    "    'num_leaves': 31,   # 전체 트리의 leave 수 (31)\n",
    "    'num_ireraions': 10000,   # 반복수행 트리개수(100)\n",
    "    'feature_fraction': 0.5,   # 개별 트리 학습시 선택되느 피쳐 비율, 과적합방지(1.0)\n",
    "    'bagging_fraction': 0.5,   # 데이터 샘플링 비율, 과적합제어(1.0)\n",
    "    \n",
    "    'objective': 'binary',\n",
    "    'min_data_in_leaf': 200,\n",
    "    'learning_rate': 0.05,\n",
    "}\n",
    "\n",
    "model = lgb.train(params, train_ds, num_boost_round=5000, valid_sets=test_ds, \n",
    "                  early_stopping_rounds=100)\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443afa92",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(y_pred)):\n",
    "    if y_pred[i]>=.5:\n",
    "        y_pred[i]=1\n",
    "    else:\n",
    "        y_pred[i]=0\n",
    "cm=confusion_matrix(y_test,y_pred)\n",
    "acc=accuracy_score(y_pred, y_test)\n",
    "print(cm)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16be1053",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# train_ds = lgb.Dataset(x_train, label = y_train)\n",
    "# test_ds = lgb.Dataset(x_val, label = y_val)\n",
    "# params = {'learning_rate': 0.01,\n",
    "#           'max_depth': 16,\n",
    "#           'boosting': 'gbdt',\n",
    "#           'objective': 'binary',\n",
    "#           'metric': 'mse',\n",
    "#           'is_training_metric': True,\n",
    "#           'num_leaves': 144,\n",
    "#           'feature_fraction': 0.9,\n",
    "#           'bagging_fraction': 0.7,\n",
    "#           'bagging_freq': 5,\n",
    "#           'seed':2020}\n",
    "\n",
    "# model = lgb.train(params, train_ds, 1000, test_ds, verbose_eval=100, early_stopping_rounds=100)\n",
    "# y_pred=model.predict(x_val)\n",
    "# pred_proba = model.predict_proba(x_test)[:,1]\n",
    "\n",
    "# # lgbm_wrapper = LGBMClassifier(n_estimators=400)\n",
    "# # evals = [(x_val, y_val)]\n",
    "# # lgbm_wrapper.fit(x_train, y_train, early_stopping_rounds=100, eval_metric='AUC', eval_set=evals, verbose=True)\n",
    "# # pred = lgbm_wrapper.predict(x_val)\n",
    "# # pred_proba = lgbm_wrapper.predict_proba(x_val)[:1]\n",
    "\n",
    "# submission= pd.read_csv('./sample_submission.csv')\n",
    "# submission['voted'] = pred_proba\n",
    "# submission.to_csv('submission_proba.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7a0110",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # model = LGBMClassifier(\n",
    "# #     objective = 'binary',\n",
    "# #     learning_rate=0.06,\n",
    "# #     num_iterations=10**4,\n",
    "# #     min_data_in_leaf=200,\n",
    "    \n",
    "# # )\n",
    "\n",
    "# # GridSearchCV의 param_grid 설정\n",
    "# params = {\n",
    "#     'learning_rate': [0.05, 0.06, 0.1],\n",
    "#     'min_data_in_leaf':[100,1000]\n",
    "# }\n",
    "\n",
    "# model = LGBMClassifier( )\n",
    "# grid_tree = GridSearchCV(model, param_grid=params, cv=3, refit=True)\n",
    "# grid_tree.fit(x_train, y_train)\n",
    "\n",
    "# print('best parameters : ', grid_tree.best_params_)\n",
    "# print('best score : ', grid_tree.best_score_)\n",
    "# em = grid_tree.best_estimator_\n",
    "# pred = em.predict(x_test)\n",
    "# accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67f0ab4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
